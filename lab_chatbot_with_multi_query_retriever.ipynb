{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5gD3ZDIwBXB"
      },
      "source": [
        "# Question Answering with LangChain, OpenAI, and MultiQuery Retriever\n",
        "\n",
        "This interactive workbook demonstrates example of Elasticsearch's [MultiQuery Retriever](https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.multi_query.MultiQueryRetriever.html) to generate similar queries for a given user input and apply all queries to retrieve a larger set of relevant documents from a vectorstore.\n",
        "\n",
        "Before we begin, we first split the fictional workplace documents into passages with `langchain` and uses OpenAI to transform these passages into embeddings and then store these into Elasticsearch.\n",
        "\n",
        "We will then ask a question, generate similar questions using langchain and OpenAI, retrieve relevant passages from the vector store, and use langchain and OpenAI again to provide a summary for the questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivL_AkmYwBXE"
      },
      "source": [
        "## Install packages and import modules"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy2aO9Fl4zC7",
        "outputId": "78dbff34-c590-479f-ca0b-deb50c1f2203"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.86.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rjHpRCifwBXF"
      },
      "outputs": [],
      "source": [
        "!python3 -m pip install -qU jq lark langchain langchain-elasticsearch langchain_openai tiktoken\n",
        "\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain_elasticsearch import ElasticsearchStore\n",
        "from langchain_openai.llms import OpenAI\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from getpass import getpass\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hngZaCjfwBXH"
      },
      "source": [
        "## Connect to Elasticsearch\n",
        "\n",
        "ℹ️ We're using an Elastic Cloud deployment of Elasticsearch for this notebook. If you don't have an Elastic Cloud deployment, sign up [here](https://cloud.elastic.co/registration?utm_source=github&utm_content=elasticsearch-labs-notebook) for a free trial.\n",
        "\n",
        "We'll use the **Cloud ID** to identify our deployment, because we are using Elastic Cloud deployment. To find the Cloud ID for your deployment, go to https://cloud.elastic.co/deployments and select your deployment.\n",
        "\n",
        "We will use [ElasticsearchStore](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html) to connect to our elastic cloud deployment, This would help create and index data easily.  We would also send list of documents that we created in the previous step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxk_EBNbwBXI",
        "outputId": "de40289d-3cee-4266-c19e-a5306776fec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Elastic Cloud ID: ··········\n",
            "Elastic API Key: ··········\n",
            "OpenAI API Key: ··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "from langchain_community.vectorstores.elasticsearch import ElasticsearchStore\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Prompt securely for credentials\n",
        "ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID: \")\n",
        "ELASTIC_API_KEY = getpass(\"Elastic API Key: \")\n",
        "OPENAI_API_KEY = getpass(\"OpenAI API Key: \")\n",
        "\n",
        "# Create OpenAI embedding model\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Set a meaningful index name\n",
        "INDEX_NAME = \"workplace-docs\"  # or any name you prefer\n",
        "\n",
        "# Create Elasticsearch vector store\n",
        "vectorstore = ElasticsearchStore(\n",
        "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
        "    es_api_key=ELASTIC_API_KEY,\n",
        "    index_name=INDEX_NAME,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yCuacwfwBXI"
      },
      "source": [
        "## Indexing Data into Elasticsearch\n",
        "Let's download the sample dataset and deserialize the document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_Ez7ex8_wBXJ"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "import json\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/example-apps/chatbot-rag-app/data/data.json\"\n",
        "\n",
        "response = urlopen(url)\n",
        "data = json.load(response)\n",
        "\n",
        "with open(\"temp.json\", \"w\") as json_file:\n",
        "    json.dump(data, json_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrisIdJxwBXJ"
      },
      "source": [
        "### Split Documents into Passages\n",
        "\n",
        "We’ll chunk documents into passages in order to improve the retrieval specificity and to ensure that we can provide multiple passages within the context window of the final question answering prompt.\n",
        "\n",
        "Here we are chunking documents into 800 token passages with an overlap of 400 tokens.\n",
        "\n",
        "Here we are using a simple splitter but Langchain offers more advanced splitters to reduce the chance of context being lost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2MbJlnBwBXL"
      },
      "source": [
        "### Bulk Import Passages\n",
        "\n",
        "Now that we have split each document into the chunk size of 800, we will now index data to elasticsearch using [ElasticsearchStore.from_documents](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.elasticsearch.ElasticsearchStore.html#langchain.vectorstores.elasticsearch.ElasticsearchStore.from_documents).\n",
        "\n",
        "We will use Cloud ID, Password and Index name values set in the `Create cloud deployment` step."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dateutil.parser import parse\n",
        "\n",
        "def metadata_func(record: dict, metadata: dict) -> dict:\n",
        "    metadata['name'] = record.get('name', 'unknown-source')\n",
        "    metadata['summary'] = record.get('summary', '')\n",
        "    metadata['url'] = record.get('url', '')\n",
        "    metadata['category'] = record.get('category', '')\n",
        "\n",
        "    updated_at = record.get('updated_at')\n",
        "    if updated_at and updated_at.strip():\n",
        "        try:\n",
        "            dt = parse(updated_at)\n",
        "            metadata['updated_at'] = dt.isoformat()\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Failed to parse date '{updated_at}' - {e}\")\n",
        "            metadata.pop('updated_at', None)\n",
        "    else:\n",
        "        metadata.pop('updated_at', None)\n",
        "\n",
        "    print(f\"Processing record, updated_at: {updated_at} -> metadata: {metadata.get('updated_at', 'Not set')}\")\n",
        "    return metadata\n"
      ],
      "metadata": {
        "id": "GDh6x7N8GeE6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import JSONLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "loader = JSONLoader(\n",
        "    file_path=\"temp.json\",\n",
        "    jq_schema=\".[]\",\n",
        "    content_key=\"content\",\n",
        "    metadata_func=metadata_func,\n",
        ")\n",
        "raw_docs = loader.load()\n",
        "for i, doc in enumerate(raw_docs[:5]):\n",
        "    print(f\"Raw Doc {i+1} content:\", doc.page_content)\n",
        "    print(f\"Raw Doc {i+1} metadata:\", doc.metadata)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "docs = loader.load_and_split(text_splitter=text_splitter)\n",
        "\n",
        "for i, doc in enumerate(docs[:3]):\n",
        "    print(f\"Doc {i+1} metadata:\", doc.metadata)\n",
        "\n",
        "for doc in docs[:3]:\n",
        "    print(doc.metadata)  # Should include 'name'\n",
        "\n",
        "\n",
        "for doc in docs:\n",
        "    if 'name' not in doc.metadata or not doc.metadata['name']:\n",
        "        doc.metadata['name'] = \"unknown-source\"\n",
        "\n",
        "vectorstore = ElasticsearchStore.from_documents(\n",
        "    docs,                # these docs with metadata!\n",
        "    embeddings,\n",
        "    index_name=\"search-ipd3\",\n",
        "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
        "    es_api_key=ELASTIC_API_KEY,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxNYVX87DLgs",
        "outputId": "71b291c6-e240-4258-cee7-0395051508cb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing record, updated_at: 2020-03-01 -> metadata: 2020-03-01T00:00:00\n",
            "Processing record, updated_at: 2022-04-29 -> metadata: 2022-04-29T00:00:00\n",
            "Processing record, updated_at: 2023-05-01 -> metadata: 2023-05-01T00:00:00\n",
            "Processing record, updated_at: 2023-04-15 -> metadata: 2023-04-15T00:00:00\n",
            "Processing record, updated_at: 2018-04-16 -> metadata: 2018-04-16T00:00:00\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Raw Doc 1 content: Effective: March 2020\n",
            "Purpose\n",
            "\n",
            "The purpose of this full-time work-from-home policy is to provide guidelines and support for employees to conduct their work remotely, ensuring the continuity and productivity of business operations during the COVID-19 pandemic and beyond.\n",
            "Scope\n",
            "\n",
            "This policy applies to all employees who are eligible for remote work as determined by their role and responsibilities. It is designed to allow employees to work from home full time while maintaining the same level of performance and collaboration as they would in the office.\n",
            "Eligibility\n",
            "\n",
            "Employees who can perform their work duties remotely and have received approval from their direct supervisor and the HR department are eligible for this work-from-home arrangement.\n",
            "Equipment and Resources\n",
            "\n",
            "The necessary equipment and resources will be provided to employees for remote work, including a company-issued laptop, software licenses, and access to secure communication tools. Employees are responsible for maintaining and protecting the company's equipment and data.\n",
            "Workspace\n",
            "\n",
            "Employees working from home are responsible for creating a comfortable and safe workspace that is conducive to productivity. This includes ensuring that their home office is ergonomically designed, well-lit, and free from distractions.\n",
            "Communication\n",
            "\n",
            "Effective communication is vital for successful remote work. Employees are expected to maintain regular communication with their supervisors, colleagues, and team members through email, phone calls, video conferences, and other approved communication tools.\n",
            "Work Hours and Availability\n",
            "\n",
            "Employees are expected to maintain their regular work hours and be available during normal business hours, unless otherwise agreed upon with their supervisor. Any changes to work hours or availability must be communicated to the employee's supervisor and the HR department.\n",
            "Performance Expectations\n",
            "\n",
            "Employees working from home are expected to maintain the same level of performance and productivity as if they were working in the office. Supervisors and team members will collaborate to establish clear expectations and goals for remote work.\n",
            "Time Tracking and Overtime\n",
            "\n",
            "Employees are required to accurately track their work hours using the company's time tracking system. Non-exempt employees must obtain approval from their supervisor before working overtime.\n",
            "Confidentiality and Data Security\n",
            "\n",
            "Employees must adhere to the company's confidentiality and data security policies while working from home. This includes safeguarding sensitive information, securing personal devices and internet connections, and reporting any security breaches to the IT department.\n",
            "Health and Well-being\n",
            "\n",
            "The company encourages employees to prioritize their health and well-being while working from home. This includes taking regular breaks, maintaining a work-life balance, and seeking support from supervisors and colleagues when needed.\n",
            "Policy Review and Updates\n",
            "\n",
            "This work-from-home policy will be reviewed periodically and updated as necessary, taking into account changes in public health guidance, business needs, and employee feedback.\n",
            "Questions and Concerns\n",
            "\n",
            "Employees are encouraged to direct any questions or concerns about this policy to their supervisor or the HR department.\n",
            "\n",
            "Raw Doc 1 metadata: {'source': '/content/temp.json', 'seq_num': 1, 'name': 'Work From Home Policy', 'summary': 'This policy outlines the guidelines for full-time remote work, including eligibility, equipment and resources, workspace requirements, communication expectations, performance expectations, time tracking and overtime, confidentiality and data security, health and well-being, and policy reviews and updates. Employees are encouraged to direct any questions or concerns', 'url': './sharepoint/Work from home policy.txt', 'category': 'teams', 'updated_at': '2020-03-01T00:00:00'}\n",
            "Raw Doc 2 content: Starting May 2022, the company will be implementing a two-day in-office work requirement per week for all eligible employees. Please coordinate with your supervisor and HR department to schedule your in-office workdays while continuing to follow all safety protocols.\n",
            "\n",
            "Raw Doc 2 metadata: {'source': '/content/temp.json', 'seq_num': 2, 'name': 'April Work From Home Update', 'summary': 'Starting May 2022, employees will need to work two days a week in the office. Coordinate with your supervisor and HR department for these days while following safety protocols.', 'url': './sharepoint/April work from home update.txt', 'category': 'teams', 'updated_at': '2022-04-29T00:00:00'}\n",
            "Raw Doc 3 content: As we continue to prioritize the well-being of our employees, we are making a slight adjustment to our hybrid work policy. Starting May 1, 2023, employees will be required to work from the office three days a week, with two days designated for remote work. Please communicate with your supervisor and HR department to establish your updated in-office workdays.\n",
            "\n",
            "Raw Doc 3 metadata: {'source': '/content/temp.json', 'seq_num': 3, 'name': 'Wfh Policy Update May 2023', 'summary': 'Starting May 1, 2023, our hybrid work policy will require employees to work from the office three days a week and two days remotely.', 'url': './sharepoint/WFH policy update May 2023.txt', 'category': 'teams', 'updated_at': '2023-05-01T00:00:00'}\n",
            "Raw Doc 4 content: Executive Summary:\n",
            "This sales strategy document outlines the key objectives, focus areas, and action plans for our tech company's sales operations in fiscal year 2024. Our primary goal is to increase revenue, expand market share, and strengthen customer relationships in our target markets.\n",
            "\n",
            "I. Objectives for Fiscal Year 2024\n",
            "\n",
            "Increase revenue by 20% compared to fiscal year 2023.\n",
            "Expand market share in key segments by 15%.\n",
            "Retain 95% of existing customers and increase customer satisfaction ratings.\n",
            "Launch at least two new products or services in high-demand market segments.\n",
            "\n",
            "II. Focus Areas\n",
            "A. Target Markets:\n",
            "Continue to serve existing markets with a focus on high-growth industries.\n",
            "Identify and penetrate new markets with high potential for our products and services.\n",
            "\n",
            "B. Customer Segmentation:\n",
            "Strengthen relationships with key accounts and strategic partners.\n",
            "Pursue new customers in underserved market segments.\n",
            "Develop tailored offerings for different customer segments based on their needs and preferences.\n",
            "\n",
            "C. Product/Service Portfolio:\n",
            "Optimize the existing product/service portfolio by focusing on high-demand solutions.\n",
            "Develop and launch innovative products/services in emerging technology areas.\n",
            "Enhance post-sales support and customer service to improve customer satisfaction.\n",
            "\n",
            "III. Action Plans\n",
            "A. Sales Team Development:\n",
            "Expand the sales team to cover new markets and industries.\n",
            "Provide ongoing training to sales staff on product knowledge, sales techniques, and industry trends.\n",
            "Implement a performance-based incentive system to reward top performers.\n",
            "\n",
            "B. Marketing and Promotion:\n",
            "Develop targeted marketing campaigns for different customer segments and industries.\n",
            "Leverage digital marketing channels to increase brand visibility and lead generation.\n",
            "Participate in industry events and trade shows to showcase our products and services.\n",
            "\n",
            "C. Partner Ecosystem:\n",
            "Strengthen existing partnerships and establish new strategic alliances to expand market reach.\n",
            "Collaborate with partners on joint marketing and sales initiatives.\n",
            "Provide partner training and support to ensure they effectively represent our products and services.\n",
            "\n",
            "D. Customer Success:\n",
            "Implement a proactive customer success program to improve customer retention and satisfaction.\n",
            "Develop a dedicated customer support team to address customer inquiries and concerns promptly.\n",
            "Collect and analyze customer feedback to identify areas for improvement in our products, services, and processes.\n",
            "\n",
            "IV. Monitoring and Evaluation\n",
            "Establish key performance indicators (KPIs) to track progress toward our objectives.\n",
            "Conduct regular sales team meetings to review performance, share best practices, and address challenges.\n",
            "Conduct quarterly reviews of our sales strategy to ensure alignment with market trends and adjust as needed.\n",
            "\n",
            "By following this sales strategy for fiscal year 2024, our tech company aims to achieve significant growth and success in our target markets, while also providing exceptional value and service to our customers.\n",
            "\n",
            "Raw Doc 4 metadata: {'source': '/content/temp.json', 'seq_num': 4, 'name': 'Fy2024 Company Sales Strategy', 'summary': \"This sales strategy document outlines objectives, focus areas, and action plans for our tech company's sales operations in fiscal year 2024. Our primary goal is to increase revenue, expand market share, and strengthen customer relationships in our target markets. Focus areas include targeting new markets, segmenting customers, enhancing\", 'url': './sharepoint/FY2024 Company Sales Strategy.txt', 'category': 'teams', 'updated_at': '2023-04-15T00:00:00'}\n",
            "Raw Doc 5 content: Purpose\n",
            "\n",
            "The purpose of this vacation policy is to outline the guidelines and procedures for requesting and taking time off from work for personal and leisure purposes. This policy aims to promote a healthy work-life balance and encourage employees to take time to rest and recharge.\n",
            "Scope\n",
            "\n",
            "This policy applies to all full-time and part-time employees who have completed their probationary period.\n",
            "Vacation Accrual\n",
            "\n",
            "Full-time employees accrue vacation time at a rate of [X hours] per month, equivalent to [Y days] per year. Part-time employees accrue vacation time on a pro-rata basis, calculated according to their scheduled work hours.\n",
            "\n",
            "Vacation time will begin to accrue from the first day of employment, but employees are eligible to take vacation time only after completing their probationary period. Unused vacation time will be carried over to the next year, up to a maximum of [Z days]. Any additional unused vacation time will be forfeited.\n",
            "Vacation Scheduling\n",
            "\n",
            "Employees are required to submit vacation requests to their supervisor at least [A weeks] in advance, specifying the start and end dates of their vacation. Supervisors will review and approve vacation requests based on business needs, ensuring adequate coverage during the employee's absence.\n",
            "\n",
            "Employees are encouraged to plan their vacations around the company's peak and non-peak periods to minimize disruptions. Vacation requests during peak periods may be subject to limitations and require additional advance notice.\n",
            "Vacation Pay\n",
            "\n",
            "Employees will receive their regular pay during their approved vacation time. Vacation pay will be calculated based on the employee's average earnings over the [B weeks] preceding their vacation.\n",
            "Unplanned Absences and Vacation Time\n",
            "\n",
            "In the event of an unplanned absence due to illness or personal emergencies, employees may use their accrued vacation time, subject to supervisor approval. Employees must inform their supervisor as soon as possible and provide any required documentation upon their return to work.\n",
            "Vacation Time and Termination of Employment\n",
            "\n",
            "If an employee's employment is terminated, they will be paid out for any unused vacation time, calculated based on their current rate of pay.\n",
            "Policy Review and Updates\n",
            "\n",
            "This vacation policy will be reviewed periodically and updated as necessary, taking into account changes in labor laws, business needs, and employee feedback.\n",
            "Questions and Concerns\n",
            "\n",
            "Employees are encouraged to direct any questions or concerns about this policy to their supervisor or the HR department.\n",
            "\n",
            "Raw Doc 5 metadata: {'source': '/content/temp.json', 'seq_num': 5, 'name': 'Company Vacation Policy', 'summary': ': This policy outlines the guidelines and procedures for requesting and taking time off from work for personal and leisure purposes. Full-time employees accrue vacation time at a rate of [X hours] per month, equivalent to [Y days] per year. Vacation requests must be submitted to supervisors at least', 'url': 'https://enterprisesearch.sharepoint.com/:t:/s/MSBuilddemo/ES6rw9bKZxVBobG1WUoJpikBF9Bhx1pw_GvJWbsg-Z_HNA?e=faSHVt', 'category': 'sharepoint', 'updated_at': '2018-04-16T00:00:00'}\n",
            "Processing record, updated_at: 2020-03-01 -> metadata: 2020-03-01T00:00:00\n",
            "Processing record, updated_at: 2022-04-29 -> metadata: 2022-04-29T00:00:00\n",
            "Processing record, updated_at: 2023-05-01 -> metadata: 2023-05-01T00:00:00\n",
            "Processing record, updated_at: 2023-04-15 -> metadata: 2023-04-15T00:00:00\n",
            "Processing record, updated_at: 2018-04-16 -> metadata: 2018-04-16T00:00:00\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Processing record, updated_at: None -> metadata: Not set\n",
            "Doc 1 metadata: {'source': '/content/temp.json', 'seq_num': 1, 'name': 'Work From Home Policy', 'summary': 'This policy outlines the guidelines for full-time remote work, including eligibility, equipment and resources, workspace requirements, communication expectations, performance expectations, time tracking and overtime, confidentiality and data security, health and well-being, and policy reviews and updates. Employees are encouraged to direct any questions or concerns', 'url': './sharepoint/Work from home policy.txt', 'category': 'teams', 'updated_at': '2020-03-01T00:00:00'}\n",
            "Doc 2 metadata: {'source': '/content/temp.json', 'seq_num': 1, 'name': 'Work From Home Policy', 'summary': 'This policy outlines the guidelines for full-time remote work, including eligibility, equipment and resources, workspace requirements, communication expectations, performance expectations, time tracking and overtime, confidentiality and data security, health and well-being, and policy reviews and updates. Employees are encouraged to direct any questions or concerns', 'url': './sharepoint/Work from home policy.txt', 'category': 'teams', 'updated_at': '2020-03-01T00:00:00'}\n",
            "Doc 3 metadata: {'source': '/content/temp.json', 'seq_num': 1, 'name': 'Work From Home Policy', 'summary': 'This policy outlines the guidelines for full-time remote work, including eligibility, equipment and resources, workspace requirements, communication expectations, performance expectations, time tracking and overtime, confidentiality and data security, health and well-being, and policy reviews and updates. Employees are encouraged to direct any questions or concerns', 'url': './sharepoint/Work from home policy.txt', 'category': 'teams', 'updated_at': '2020-03-01T00:00:00'}\n",
            "{'source': '/content/temp.json', 'seq_num': 1, 'name': 'Work From Home Policy', 'summary': 'This policy outlines the guidelines for full-time remote work, including eligibility, equipment and resources, workspace requirements, communication expectations, performance expectations, time tracking and overtime, confidentiality and data security, health and well-being, and policy reviews and updates. Employees are encouraged to direct any questions or concerns', 'url': './sharepoint/Work from home policy.txt', 'category': 'teams', 'updated_at': '2020-03-01T00:00:00'}\n",
            "{'source': '/content/temp.json', 'seq_num': 1, 'name': 'Work From Home Policy', 'summary': 'This policy outlines the guidelines for full-time remote work, including eligibility, equipment and resources, workspace requirements, communication expectations, performance expectations, time tracking and overtime, confidentiality and data security, health and well-being, and policy reviews and updates. Employees are encouraged to direct any questions or concerns', 'url': './sharepoint/Work from home policy.txt', 'category': 'teams', 'updated_at': '2020-03-01T00:00:00'}\n",
            "{'source': '/content/temp.json', 'seq_num': 1, 'name': 'Work From Home Policy', 'summary': 'This policy outlines the guidelines for full-time remote work, including eligibility, equipment and resources, workspace requirements, communication expectations, performance expectations, time tracking and overtime, confidentiality and data security, health and well-being, and policy reviews and updates. Employees are encouraged to direct any questions or concerns', 'url': './sharepoint/Work from home policy.txt', 'category': 'teams', 'updated_at': '2020-03-01T00:00:00'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zr-y6EVkwBXM"
      },
      "outputs": [],
      "source": [
        "vectorstore = ElasticsearchStore.from_documents(\n",
        "    docs,\n",
        "    embeddings,\n",
        "    index_name=\"search-ipd3\",\n",
        "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
        "    es_api_key=ELASTIC_API_KEY,\n",
        ")\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "retriever = MultiQueryRetriever.from_llm(vectorstore.as_retriever(), llm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ0aRsG9wBXM"
      },
      "source": [
        "# Question Answering with MultiQuery Retriever\n",
        "\n",
        "Now that we have the passages stored in Elasticsearch, we can now ask a question to get the relevant passages."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.vectorstores.elasticsearch import ElasticsearchStore\n",
        "from langchain.retrievers import MultiQueryRetriever\n",
        "from langchain.schema.runnable import Runnable, RunnableParallel, RunnablePassthrough\n",
        "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
        "from langchain.schema import format_document\n",
        "import logging\n",
        "\n",
        "logging.basicConfig()\n",
        "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)\n",
        "\n",
        "# Create vectorstore from documents (docs, embeddings, ELASTIC_* keys assumed defined)\n",
        "vectorstore = ElasticsearchStore.from_documents(\n",
        "    docs,\n",
        "    embeddings,\n",
        "    index_name=\"search-ipd3\",\n",
        "    es_cloud_id=ELASTIC_CLOUD_ID,\n",
        "    es_api_key=ELASTIC_API_KEY,\n",
        ")\n",
        "\n",
        "# Initialize OpenAI LLM\n",
        "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "# Create MultiQueryRetriever from vectorstore retriever + LLM\n",
        "retriever = MultiQueryRetriever.from_llm(vectorstore.as_retriever(), llm)\n",
        "\n",
        "# Prompt templates\n",
        "LLM_CONTEXT_PROMPT = ChatPromptTemplate.from_template(\n",
        "    \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Be as verbose and educational in your response as possible.\n",
        "\n",
        "    context: {context}\n",
        "    Question: \"{question}\"\n",
        "    Answer:\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "LLM_DOCUMENT_PROMPT = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "---\n",
        "SOURCE: {name}\n",
        "{page_content}\n",
        "---\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "# Runnable class for combining docs into a single string\n",
        "class CombineDocumentsRunnable(Runnable):\n",
        "    def invoke(self, docs, *args, **kwargs):\n",
        "        for doc in docs:\n",
        "            if 'name' not in doc.metadata or not doc.metadata['name']:\n",
        "                doc.metadata['name'] = \"unknown-source\"\n",
        "        doc_strings = [format_document(doc, LLM_DOCUMENT_PROMPT) for doc in docs]\n",
        "        return \"\\n\\n\".join(doc_strings)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "_combine_documents = CombineDocumentsRunnable()\n",
        "\n",
        "# Build the runnable chain\n",
        "_context = RunnableParallel(\n",
        "    context=retriever | _combine_documents,\n",
        "    question=RunnablePassthrough(),\n",
        ")\n",
        "\n",
        "chain = _context | LLM_CONTEXT_PROMPT | llm\n",
        "\n",
        "# Ask your question\n",
        "ans = chain.invoke(\"what is the nasa sales team?\")\n",
        "\n",
        "print(\"---- Answer ----\")\n",
        "print(ans)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSHTqjLVEtBR",
        "outputId": "697fa94b-1847-4a6c-87c8-3a108916c90b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: ['1. Can you provide information on the sales team at NASA?', '2. How does the sales team operate within NASA?', '3. What are the responsibilities of the NASA sales team?']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Answer ----\n",
            "The NASA sales team is a part of the Americas region in the sales organization. It is responsible for serving customers in North America and South America, with two Area Vice-Presidents, Laura Martinez and Gary Johnson. The team works closely with other departments to identify and pursue new business opportunities, nurture existing client relationships, and ensure customer satisfaction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQLK4HHdwBXN"
      },
      "source": [
        "**Generate at least two new iteratioins of the previous cells - Be creative.** Did you master Multi-\n",
        "Query Retriever concepts through this lab?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = chain.invoke(\"What is the NASA sales team and how do they operate?\")\n",
        "\n",
        "print(\"---- Chain-of-Thought Answer ----\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22jXzBsRJnw7",
        "outputId": "33e7183c-fd4d-4dc9-a845-c49767f8374b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: ['1. How does the NASA sales team function and what are their operations?', '2. Can you explain the operations of the NASA sales team and their role?', '3. What are the functions and operations of the NASA sales team?']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Chain-of-Thought Answer ----\n",
            "The NASA sales team is a part of the Americas region in the sales organization. It is responsible for serving customers in North America and South America. The team is led by two Area Vice-Presidents, Laura Martinez for North America and Gary Johnson for South America. The team consists of dedicated account managers, sales representatives, and support staff who work together to identify and pursue new business opportunities, maintain existing client relationships, and ensure customer satisfaction. They also collaborate closely with other departments, such as marketing, product development, and customer support, to deliver high-quality products and services to clients.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = chain.invoke(\"How does NASA approach sustainability and environmental impact?\")\n",
        "\n",
        "print(\"---- Chain-of-Thought Answer ----\")\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcIVTqBbKCOH",
        "outputId": "b6c66613-c788-4116-f97d-d2335a42a567"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:langchain.retrievers.multi_query:Generated queries: [\"1. What is NASA's approach to sustainability and environmental impact?\", '2. How does NASA address sustainability and environmental impact?', '3. In what ways does NASA tackle sustainability and environmental impact?']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Chain-of-Thought Answer ----\n",
            "\n",
            "NASA, or the North America South America region, is a part of the sales organization that serves customers in the United States, Canada, Mexico, Central America, and South America. While the main focus of NASA is on achieving business objectives and serving customers, it is also important to note that NASA is committed to sustainability and minimizing its environmental impact. This is evident in the fact that NASA has two Area Vice-Presidents, Laura Martinez and Gary Johnson, who oversee the region and are responsible for ensuring that sustainability practices are implemented and environmental impact is minimized. This approach to sustainability and environmental impact is crucial in today's world, where businesses are increasingly expected to prioritize and address environmental concerns. By having dedicated leaders and a structured organization, NASA is able to effectively incorporate sustainability into its operations and contribute to a more sustainable future.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}